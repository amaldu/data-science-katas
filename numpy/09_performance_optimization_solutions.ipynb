{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Optimization - Solutions\n",
    "\n",
    "NumPy vs Python performance, vectorization, and optimization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Compare the performance of summing elements using Python lists vs NumPy arrays using %timeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create test data\n",
    "size = 100000\n",
    "python_list = list(range(size))\n",
    "numpy_array = np.arange(size)\n",
    "\n",
    "print(f\"Data size: {size:,} elements\")\n",
    "print(f\"\\nPython list sum:\")\n",
    "%timeit sum(python_list)\n",
    "\n",
    "print(f\"\\nNumPy array sum:\")\n",
    "%timeit numpy_array.sum()\n",
    "\n",
    "print(f\"\\nNumPy np.sum():\")\n",
    "%timeit np.sum(numpy_array)\n",
    "\n",
    "# Manual calculation for comparison\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "result_python = sum(python_list)\n",
    "python_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "result_numpy = numpy_array.sum()\n",
    "numpy_time = time.time() - start\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Python sum: {result_python}\")\n",
    "print(f\"NumPy sum: {result_numpy}\")\n",
    "print(f\"Speed improvement: {python_time / numpy_time:.1f}x faster with NumPy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Demonstrate the performance difference between using loops and vectorized operations for element-wise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create large arrays for testing\n",
    "size = 1000000\n",
    "arr1 = np.random.rand(size)\n",
    "arr2 = np.random.rand(size)\n",
    "\n",
    "print(f\"Array size: {size:,} elements\")\n",
    "\n",
    "# Method 1: Using explicit Python loop (slow)\n",
    "def multiply_with_loop(a, b):\n",
    "    result = np.empty_like(a)\n",
    "    for i in range(len(a)):\n",
    "        result[i] = a[i] * b[i]\n",
    "    return result\n",
    "\n",
    "# Method 2: Using list comprehension (still slow)\n",
    "def multiply_with_list_comp(a, b):\n",
    "    return np.array([a[i] * b[i] for i in range(len(a))])\n",
    "\n",
    "# Method 3: Vectorized NumPy operation (fast)\n",
    "def multiply_vectorized(a, b):\n",
    "    return a * b\n",
    "\n",
    "# Time each method\n",
    "print(\"\\nTiming different methods:\")\n",
    "\n",
    "# Use smaller arrays for loop methods to avoid long wait times\n",
    "small_size = 10000\n",
    "small_arr1 = arr1[:small_size]\n",
    "small_arr2 = arr2[:small_size]\n",
    "\n",
    "start = time.time()\n",
    "result_loop = multiply_with_loop(small_arr1, small_arr2)\n",
    "loop_time = time.time() - start\n",
    "print(f\"Loop method ({small_size:,} elements): {loop_time:.4f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "result_vectorized = multiply_vectorized(arr1, arr2)\n",
    "vectorized_time = time.time() - start\n",
    "print(f\"Vectorized method ({size:,} elements): {vectorized_time:.4f} seconds\")\n",
    "\n",
    "# Calculate relative performance\n",
    "extrapolated_loop_time = loop_time * (size / small_size)\n",
    "print(f\"\\nExtrapolated loop time for {size:,} elements: {extrapolated_loop_time:.4f} seconds\")\n",
    "print(f\"Speed improvement: {extrapolated_loop_time / vectorized_time:.0f}x faster with vectorization\")\n",
    "\n",
    "# Verify results are the same\n",
    "print(f\"\\nResults are equivalent: {np.allclose(result_loop, result_vectorized[:small_size])}\")\n",
    "\n",
    "# Using %timeit for more accurate timing\n",
    "print(f\"\\nMore precise timing with %timeit:\")\n",
    "print(f\"Vectorized operation:\")\n",
    "%timeit arr1 * arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Compare memory usage between Python lists and NumPy arrays for the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Create test data\n",
    "size = 100000\n",
    "python_list = list(range(size))\n",
    "numpy_array = np.arange(size, dtype=np.int64)\n",
    "numpy_array_int32 = np.arange(size, dtype=np.int32)\n",
    "\n",
    "# Calculate memory usage\n",
    "list_memory = sys.getsizeof(python_list) + sum(sys.getsizeof(item) for item in python_list)\n",
    "numpy_memory = numpy_array.nbytes\n",
    "numpy_int32_memory = numpy_array_int32.nbytes\n",
    "\n",
    "print(f\"Data size: {size:,} integers\")\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(f\"Python list: {list_memory:,} bytes ({list_memory / 1024 / 1024:.2f} MB)\")\n",
    "print(f\"NumPy array (int64): {numpy_memory:,} bytes ({numpy_memory / 1024 / 1024:.2f} MB)\")\n",
    "print(f\"NumPy array (int32): {numpy_int32_memory:,} bytes ({numpy_int32_memory / 1024 / 1024:.2f} MB)\")\n",
    "\n",
    "print(f\"\\nMemory efficiency:\")\n",
    "print(f\"NumPy (int64) uses {list_memory / numpy_memory:.1f}x less memory than Python list\")\n",
    "print(f\"NumPy (int32) uses {list_memory / numpy_int32_memory:.1f}x less memory than Python list\")\n",
    "\n",
    "# Show per-element memory usage\n",
    "print(f\"\\nPer-element memory usage:\")\n",
    "print(f\"Python list: {list_memory / size:.1f} bytes per element\")\n",
    "print(f\"NumPy int64: {numpy_array.itemsize} bytes per element\")\n",
    "print(f\"NumPy int32: {numpy_array_int32.itemsize} bytes per element\")\n",
    "\n",
    "# Demonstrate with different data types\n",
    "print(f\"\\nMemory usage for different NumPy data types ({size:,} elements):\")\n",
    "dtypes = [np.int8, np.int16, np.int32, np.int64, np.float32, np.float64]\n",
    "for dtype in dtypes:\n",
    "    arr = np.arange(size, dtype=dtype)\n",
    "    print(f\"{dtype.__name__:>8}: {arr.nbytes:>8,} bytes ({arr.itemsize} bytes per element)\")\n",
    "\n",
    "print(f\"\\nKey takeaway: NumPy arrays are much more memory-efficient than Python lists\")\n",
    "print(f\"Choose appropriate data types to optimize memory usage further\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Show the performance impact of data type choices by comparing operations on int32 vs int64 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "size = 5000000\n",
    "data = np.random.randint(0, 1000, size)\n",
    "\n",
    "# Create arrays with different data types\n",
    "arr_int32 = data.astype(np.int32)\n",
    "arr_int64 = data.astype(np.int64)\n",
    "arr_float32 = data.astype(np.float32)\n",
    "arr_float64 = data.astype(np.float64)\n",
    "\n",
    "print(f\"Array size: {size:,} elements\")\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(f\"int32:   {arr_int32.nbytes:>10,} bytes\")\n",
    "print(f\"int64:   {arr_int64.nbytes:>10,} bytes\")\n",
    "print(f\"float32: {arr_float32.nbytes:>10,} bytes\")\n",
    "print(f\"float64: {arr_float64.nbytes:>10,} bytes\")\n",
    "\n",
    "def time_operation(arr, operation_name, func):\n",
    "    start = time.time()\n",
    "    result = func(arr)\n",
    "    elapsed = time.time() - start\n",
    "    return elapsed, result\n",
    "\n",
    "# Test different operations\n",
    "operations = [\n",
    "    (\"Sum\", lambda x: x.sum()),\n",
    "    (\"Mean\", lambda x: x.mean()),\n",
    "    (\"Square\", lambda x: x ** 2),\n",
    "    (\"Sort\", lambda x: np.sort(x))\n",
    "]\n",
    "\n",
    "print(f\"\\nPerformance comparison:\")\n",
    "print(f\"{'Operation':<10} {'int32':<10} {'int64':<10} {'float32':<10} {'float64':<10} {'Speedup':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for op_name, op_func in operations:\n",
    "    time_int32, _ = time_operation(arr_int32, op_name, op_func)\n",
    "    time_int64, _ = time_operation(arr_int64, op_name, op_func)\n",
    "    time_float32, _ = time_operation(arr_float32, op_name, op_func)\n",
    "    time_float64, _ = time_operation(arr_float64, op_name, op_func)\n",
    "    \n",
    "    speedup = time_int64 / time_int32\n",
    "    \n",
    "    print(f\"{op_name:<10} {time_int32:<10.4f} {time_int64:<10.4f} {time_float32:<10.4f} {time_float64:<10.4f} {speedup:<10.2f}x\")\n",
    "\n",
    "# More detailed timing using %timeit\n",
    "print(f\"\\nDetailed timing with %timeit:\")\n",
    "print(f\"\\nSum operation:\")\n",
    "print(f\"int32:\")\n",
    "%timeit arr_int32.sum()\n",
    "print(f\"int64:\")\n",
    "%timeit arr_int64.sum()\n",
    "\n",
    "print(f\"\\nSquare operation:\")\n",
    "print(f\"int32:\")\n",
    "%timeit arr_int32 ** 2\n",
    "print(f\"int64:\")\n",
    "%timeit arr_int64 ** 2\n",
    "\n",
    "print(f\"\\nKey insights:\")\n",
    "print(f\"- Smaller data types often perform better due to:\")\n",
    "print(f\"  * Better cache utilization\")\n",
    "print(f\"  * Less memory bandwidth required\")\n",
    "print(f\"  * More elements fit in CPU registers\")\n",
    "print(f\"- Choose the smallest data type that fits your data range\")\n",
    "print(f\"- Trade-off between precision and performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Demonstrate the performance benefit of avoiding array copies by using views when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "large_array = np.random.rand(10000, 1000)\n",
    "print(f\"Large array shape: {large_array.shape}\")\n",
    "print(f\"Array size: {large_array.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Operations that create views (fast)\n",
    "print(f\"\\nOperations that create views (no copying):\")\n",
    "\n",
    "start = time.time()\n",
    "view_slice = large_array[1000:2000, :]\n",
    "time_view_slice = time.time() - start\n",
    "print(f\"Slicing: {time_view_slice:.6f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "view_transpose = large_array.T\n",
    "time_view_transpose = time.time() - start\n",
    "print(f\"Transpose: {time_view_transpose:.6f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "view_reshape = large_array.reshape(-1)\n",
    "time_view_reshape = time.time() - start\n",
    "print(f\"Reshape: {time_view_reshape:.6f} seconds\")\n",
    "\n",
    "# Operations that create copies (slow)\n",
    "print(f\"\\nOperations that create copies (memory allocation):\")\n",
    "\n",
    "start = time.time()\n",
    "copy_slice = large_array[1000:2000, :].copy()\n",
    "time_copy_slice = time.time() - start\n",
    "print(f\"Slicing + copy(): {time_copy_slice:.6f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "copy_explicit = np.copy(large_array)\n",
    "time_copy_explicit = time.time() - start\n",
    "print(f\"np.copy(): {time_copy_explicit:.6f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "copy_fancy = large_array[[1, 3, 5, 7], :]\n",
    "time_copy_fancy = time.time() - start\n",
    "print(f\"Fancy indexing: {time_copy_fancy:.6f} seconds\")\n",
    "\n",
    "# Verify views vs copies\n",
    "print(f\"\\nVerifying views vs copies:\")\n",
    "print(f\"Slice shares memory: {np.shares_memory(large_array, view_slice)}\")\n",
    "print(f\"Transpose shares memory: {np.shares_memory(large_array, view_transpose)}\")\n",
    "print(f\"Reshape shares memory: {np.shares_memory(large_array, view_reshape)}\")\n",
    "print(f\"Copy shares memory: {np.shares_memory(large_array, copy_explicit)}\")\n",
    "print(f\"Fancy indexing shares memory: {np.shares_memory(large_array, copy_fancy)}\")\n",
    "\n",
    "# Demonstrate modification through views\n",
    "print(f\"\\nDemonstrating view modification:\")\n",
    "test_array = np.arange(12).reshape(3, 4)\n",
    "print(f\"Original array:\\n{test_array}\")\n",
    "\n",
    "# Create a view and modify it\n",
    "view = test_array[1:, 1:3]\n",
    "print(f\"View (rows 1:, cols 1:3):\\n{view}\")\n",
    "\n",
    "view[0, 0] = 999\n",
    "print(f\"After modifying view[0,0] = 999:\")\n",
    "print(f\"Original array:\\n{test_array}\")\n",
    "print(f\"View:\\n{view}\")\n",
    "\n",
    "# Performance implications\n",
    "print(f\"\\nPerformance implications:\")\n",
    "print(f\"- Views are created instantly (no memory allocation)\")\n",
    "print(f\"- Copies require time proportional to data size\")\n",
    "print(f\"- Use views when you don't need independent data\")\n",
    "print(f\"- Use copies when you need to modify data independently\")\n",
    "\n",
    "# Timing with %timeit\n",
    "print(f\"\\nTiming with %timeit:\")\n",
    "print(f\"View creation (transpose):\")\n",
    "%timeit large_array.T\n",
    "\n",
    "print(f\"Copy creation:\")\n",
    "%timeit large_array.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Compare the performance of using np.sum() vs Python's built-in sum() function on NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create test arrays of different sizes\n",
    "sizes = [1000, 10000, 100000, 1000000]\n",
    "\n",
    "print(f\"Performance comparison: np.sum() vs Python sum()\")\n",
    "print(f\"{'Size':<10} {'np.sum()':<12} {'Python sum()':<15} {'Speedup':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for size in sizes:\n",
    "    arr = np.random.rand(size)\n",
    "    \n",
    "    # Time np.sum()\n",
    "    start = time.time()\n",
    "    for _ in range(10):  # Average over multiple runs\n",
    "        result_numpy = np.sum(arr)\n",
    "    numpy_time = (time.time() - start) / 10\n",
    "    \n",
    "    # Time Python sum() - but only for smaller arrays as it's very slow\n",
    "    if size <= 100000:\n",
    "        start = time.time()\n",
    "        for _ in range(10):\n",
    "            result_python = sum(arr)\n",
    "        python_time = (time.time() - start) / 10\n",
    "        speedup = python_time / numpy_time\n",
    "        \n",
    "        print(f\"{size:<10,} {numpy_time:<12.6f} {python_time:<15.6f} {speedup:<10.1f}x\")\n",
    "    else:\n",
    "        print(f\"{size:<10,} {numpy_time:<12.6f} {'too slow':<15} {'>>1000':<10}x\")\n",
    "\n",
    "# Detailed analysis with %timeit for a specific size\n",
    "test_size = 50000\n",
    "test_array = np.random.rand(test_size)\n",
    "\n",
    "print(f\"\\nDetailed timing for {test_size:,} elements:\")\n",
    "print(f\"\\nnp.sum(array):\")\n",
    "%timeit np.sum(test_array)\n",
    "\n",
    "print(f\"\\narray.sum():\")\n",
    "%timeit test_array.sum()\n",
    "\n",
    "print(f\"\\nsum(array) [Python built-in]:\")\n",
    "%timeit sum(test_array)\n",
    "\n",
    "# Test with different data types\n",
    "print(f\"\\nPerformance with different data types:\")\n",
    "size = 100000\n",
    "dtypes = [np.int32, np.int64, np.float32, np.float64]\n",
    "\n",
    "for dtype in dtypes:\n",
    "    arr = np.random.randint(0, 100, size).astype(dtype)\n",
    "    \n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        result = np.sum(arr)\n",
    "    avg_time = (time.time() - start) / 10\n",
    "    \n",
    "    print(f\"{dtype.__name__:<8}: {avg_time:.6f} seconds\")\n",
    "\n",
    "# Verify results are the same (within floating point precision)\n",
    "arr_small = np.random.rand(1000)\n",
    "numpy_result = np.sum(arr_small)\n",
    "python_result = sum(arr_small)\n",
    "\n",
    "print(f\"\\nResult verification:\")\n",
    "print(f\"np.sum() result: {numpy_result}\")\n",
    "print(f\"sum() result: {python_result}\")\n",
    "print(f\"Results are close: {np.isclose(numpy_result, python_result)}\")\n",
    "print(f\"Difference: {abs(numpy_result - python_result)}\")\n",
    "\n",
    "print(f\"\\nKey takeaways:\")\n",
    "print(f\"- np.sum() is orders of magnitude faster than Python's sum()\")\n",
    "print(f\"- The speed difference increases with array size\")\n",
    "print(f\"- Both array.sum() and np.sum() are equivalent and fast\")\n",
    "print(f\"- Always use NumPy functions for NumPy arrays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Show the performance difference between using np.dot() and manual matrix multiplication with loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def manual_matrix_multiply(A, B):\n",
    "    \"\"\"Manual matrix multiplication using nested loops\"\"\"\n",
    "    rows_A, cols_A = A.shape\n",
    "    rows_B, cols_B = B.shape\n",
    "    \n",
    "    if cols_A != rows_B:\n",
    "        raise ValueError(\"Matrix dimensions incompatible\")\n",
    "    \n",
    "    result = np.zeros((rows_A, cols_B))\n",
    "    \n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_B):\n",
    "            for k in range(cols_A):\n",
    "                result[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test with different matrix sizes\n",
    "sizes = [50, 100, 200]\n",
    "\n",
    "print(f\"Matrix multiplication performance comparison\")\n",
    "print(f\"{'Size':<10} {'Manual (s)':<12} {'np.dot (s)':<12} {'@ operator (s)':<15} {'Speedup':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for size in sizes:\n",
    "    # Create random matrices\n",
    "    A = np.random.rand(size, size)\n",
    "    B = np.random.rand(size, size)\n",
    "    \n",
    "    # Time manual multiplication (only for smaller sizes)\n",
    "    if size <= 100:\n",
    "        start = time.time()\n",
    "        result_manual = manual_matrix_multiply(A, B)\n",
    "        manual_time = time.time() - start\n",
    "    else:\n",
    "        manual_time = float('inf')\n",
    "        result_manual = None\n",
    "    \n",
    "    # Time np.dot()\n",
    "    start = time.time()\n",
    "    result_dot = np.dot(A, B)\n",
    "    dot_time = time.time() - start\n",
    "    \n",
    "    # Time @ operator\n",
    "    start = time.time()\n",
    "    result_at = A @ B\n",
    "    at_time = time.time() - start\n",
    "    \n",
    "    if manual_time != float('inf'):\n",
    "        speedup = manual_time / dot_time\n",
    "        print(f\"{size}x{size:<6} {manual_time:<12.4f} {dot_time:<12.6f} {at_time:<15.6f} {speedup:<10.0f}x\")\n",
    "        \n",
    "        # Verify results are the same\n",
    "        if result_manual is not None:\n",
    "            assert np.allclose(result_manual, result_dot), \"Results don't match!\"\n",
    "            assert np.allclose(result_dot, result_at), \"np.dot and @ don't match!\"\n",
    "    else:\n",
    "        print(f\"{size}x{size:<6} {'too slow':<12} {dot_time:<12.6f} {at_time:<15.6f} {'>10000':<10}x\")\n",
    "\n",
    "# Detailed timing for medium-sized matrices\n",
    "print(f\"\\nDetailed timing for 100x100 matrices:\")\n",
    "A = np.random.rand(100, 100)\n",
    "B = np.random.rand(100, 100)\n",
    "\n",
    "print(f\"\\nnp.dot(A, B):\")\n",
    "%timeit np.dot(A, B)\n",
    "\n",
    "print(f\"\\nA @ B:\")\n",
    "%timeit A @ B\n",
    "\n",
    "print(f\"\\nnp.matmul(A, B):\")\n",
    "%timeit np.matmul(A, B)\n",
    "\n",
    "# Test with different matrix shapes\n",
    "print(f\"\\nPerformance with different matrix shapes:\")\n",
    "shapes = [(100, 200, 150), (500, 100, 300), (200, 500, 100)]\n",
    "\n",
    "for m, k, n in shapes:\n",
    "    A = np.random.rand(m, k)\n",
    "    B = np.random.rand(k, n)\n",
    "    \n",
    "    start = time.time()\n",
    "    result = A @ B\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"({m}x{k}) @ ({k}x{n}) = ({m}x{n}): {elapsed:.4f} seconds\")\n",
    "\n",
    "# Show why NumPy is faster\n",
    "print(f\"\\nWhy NumPy is faster:\")\n",
    "print(f\"- Uses optimized BLAS (Basic Linear Algebra Subprograms) libraries\")\n",
    "print(f\"- Written in C/Fortran, not Python\")\n",
    "print(f\"- Optimized for cache efficiency and vectorization\")\n",
    "print(f\"- Can use multiple CPU cores (depending on BLAS implementation)\")\n",
    "print(f\"- Avoids Python's interpreter overhead for inner loops\")\n",
    "\n",
    "# Check which BLAS is being used\n",
    "print(f\"\\nBLAS information:\")\n",
    "try:\n",
    "    print(f\"NumPy build configuration:\")\n",
    "    np.show_config()\n",
    "except:\n",
    "    print(f\"Unable to show BLAS configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "Demonstrate the impact of memory layout (C-order vs Fortran-order) on performance for different operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "size = 2000\n",
    "# Create arrays with different memory layouts\n",
    "arr_c = np.random.rand(size, size)  # C-order (row-major)\n",
    "arr_f = np.asfortranarray(arr_c)    # Fortran-order (column-major)\n",
    "\n",
    "print(f\"Array shape: {arr_c.shape}\")\n",
    "print(f\"C-order array flags: C_CONTIGUOUS={arr_c.flags['C_CONTIGUOUS']}, F_CONTIGUOUS={arr_c.flags['F_CONTIGUOUS']}\")\n",
    "print(f\"F-order array flags: C_CONTIGUOUS={arr_f.flags['C_CONTIGUOUS']}, F_CONTIGUOUS={arr_f.flags['F_CONTIGUOUS']}\")\n",
    "\n",
    "def time_operation(arr, name, operation):\n",
    "    start = time.time()\n",
    "    result = operation(arr)\n",
    "    elapsed = time.time() - start\n",
    "    return elapsed\n",
    "\n",
    "# Test row-wise operations (should be faster for C-order)\n",
    "print(f\"\\nRow-wise operations (should favor C-order):\")\n",
    "print(f\"{'Operation':<20} {'C-order':<10} {'F-order':<10} {'Ratio':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Row sum\n",
    "time_c = time_operation(arr_c, \"Row sum C\", lambda x: x.sum(axis=1))\n",
    "time_f = time_operation(arr_f, \"Row sum F\", lambda x: x.sum(axis=1))\n",
    "print(f\"{'Row sum':<20} {time_c:<10.4f} {time_f:<10.4f} {time_f/time_c:<10.2f}\")\n",
    "\n",
    "# Row iteration (accessing consecutive elements)\n",
    "def row_iteration(arr):\n",
    "    total = 0\n",
    "    for i in range(min(100, arr.shape[0])):  # Limited iterations for timing\n",
    "        total += arr[i, :].sum()\n",
    "    return total\n",
    "\n",
    "time_c = time_operation(arr_c, \"Row iter C\", row_iteration)\n",
    "time_f = time_operation(arr_f, \"Row iter F\", row_iteration)\n",
    "print(f\"{'Row iteration':<20} {time_c:<10.4f} {time_f:<10.4f} {time_f/time_c:<10.2f}\")\n",
    "\n",
    "# Test column-wise operations (should be faster for F-order)\n",
    "print(f\"\\nColumn-wise operations (should favor F-order):\")\n",
    "print(f\"{'Operation':<20} {'C-order':<10} {'F-order':<10} {'Ratio':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Column sum\n",
    "time_c = time_operation(arr_c, \"Col sum C\", lambda x: x.sum(axis=0))\n",
    "time_f = time_operation(arr_f, \"Col sum F\", lambda x: x.sum(axis=0))\n",
    "print(f\"{'Column sum':<20} {time_c:<10.4f} {time_f:<10.4f} {time_c/time_f:<10.2f}\")\n",
    "\n",
    "# Column iteration\n",
    "def col_iteration(arr):\n",
    "    total = 0\n",
    "    for j in range(min(100, arr.shape[1])):\n",
    "        total += arr[:, j].sum()\n",
    "    return total\n",
    "\n",
    "time_c = time_operation(arr_c, \"Col iter C\", col_iteration)\n",
    "time_f = time_operation(arr_f, \"Col iter F\", col_iteration)\n",
    "print(f\"{'Column iteration':<20} {time_c:<10.4f} {time_f:<10.4f} {time_c/time_f:<10.2f}\")\n",
    "\n",
    "# Test operations that don't care about layout\n",
    "print(f\"\\nLayout-agnostic operations:\")\n",
    "print(f\"{'Operation':<20} {'C-order':<10} {'F-order':<10} {'Ratio':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Element-wise operations\n",
    "time_c = time_operation(arr_c, \"Square C\", lambda x: x ** 2)\n",
    "time_f = time_operation(arr_f, \"Square F\", lambda x: x ** 2)\n",
    "print(f\"{'Element-wise square':<20} {time_c:<10.4f} {time_f:<10.4f} {abs(time_f-time_c)/min(time_c,time_f):<10.2f}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "arr_c_small = arr_c[:500, :500]\n",
    "arr_f_small = arr_f[:500, :500]\n",
    "\n",
    "time_c = time_operation(arr_c_small, \"MatMul C\", lambda x: x @ x.T)\n",
    "time_f = time_operation(arr_f_small, \"MatMul F\", lambda x: x @ x.T)\n",
    "print(f\"{'Matrix multiply':<20} {time_c:<10.4f} {time_f:<10.4f} {abs(time_f-time_c)/min(time_c,time_f):<10.2f}\")\n",
    "\n",
    "# Demonstrate cache effects with detailed timing\n",
    "print(f\"\\nDetailed cache effects demonstration:\")\n",
    "small_size = 1000\n",
    "arr_c_small = np.random.rand(small_size, small_size)\n",
    "arr_f_small = np.asfortranarray(arr_c_small)\n",
    "\n",
    "print(f\"\\nRow-wise access (C-order should be faster):\")\n",
    "print(f\"C-order array, row access:\")\n",
    "%timeit arr_c_small.sum(axis=1)\n",
    "\n",
    "print(f\"F-order array, row access:\")\n",
    "%timeit arr_f_small.sum(axis=1)\n",
    "\n",
    "print(f\"\\nColumn-wise access (F-order should be faster):\")\n",
    "print(f\"C-order array, column access:\")\n",
    "%timeit arr_c_small.sum(axis=0)\n",
    "\n",
    "print(f\"F-order array, column access:\")\n",
    "%timeit arr_f_small.sum(axis=0)\n",
    "\n",
    "print(f\"\\nKey insights:\")\n",
    "print(f\"- Memory layout affects cache performance\")\n",
    "print(f\"- C-order (row-major): consecutive elements in rows are adjacent in memory\")\n",
    "print(f\"- F-order (column-major): consecutive elements in columns are adjacent in memory\")\n",
    "print(f\"- Accessing data in memory order is faster due to cache locality\")\n",
    "print(f\"- Most NumPy operations are optimized for both layouts\")\n",
    "print(f\"- Choose layout based on your primary access pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "Compare the performance of using boolean indexing vs np.where() for conditional operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create test data\n",
    "size = 1000000\n",
    "arr = np.random.randn(size)  # Random normal distribution\n",
    "\n",
    "print(f\"Array size: {size:,} elements\")\n",
    "print(f\"Task: Replace negative values with 0, keep positive values\")\n",
    "\n",
    "def method_boolean_indexing(arr):\n",
    "    \"\"\"Using boolean indexing\"\"\"\n",
    "    result = arr.copy()\n",
    "    result[result < 0] = 0\n",
    "    return result\n",
    "\n",
    "def method_where(arr):\n",
    "    \"\"\"Using np.where\"\"\"\n",
    "    return np.where(arr < 0, 0, arr)\n",
    "\n",
    "def method_maximum(arr):\n",
    "    \"\"\"Using np.maximum (specialized for this case)\"\"\"\n",
    "    return np.maximum(arr, 0)\n",
    "\n",
    "def method_clip(arr):\n",
    "    \"\"\"Using np.clip (specialized for this case)\"\"\"\n",
    "    return np.clip(arr, 0, None)\n",
    "\n",
    "# Time each method\n",
    "methods = [\n",
    "    (\"Boolean indexing\", method_boolean_indexing),\n",
    "    (\"np.where\", method_where),\n",
    "    (\"np.maximum\", method_maximum),\n",
    "    (\"np.clip\", method_clip)\n",
    "]\n",
    "\n",
    "print(f\"\\nPerformance comparison:\")\n",
    "print(f\"{'Method':<20} {'Time (s)':<10} {'Relative':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "times = []\n",
    "results = []\n",
    "\n",
    "for name, method in methods:\n",
    "    start = time.time()\n",
    "    for _ in range(10):  # Average over multiple runs\n",
    "        result = method(arr)\n",
    "    elapsed = (time.time() - start) / 10\n",
    "    \n",
    "    times.append(elapsed)\n",
    "    results.append(result)\n",
    "    relative = elapsed / times[0] if times[0] > 0 else 1\n",
    "    \n",
    "    print(f\"{name:<20} {elapsed:<10.6f} {relative:<10.2f}x\")\n",
    "\n",
    "# Verify all methods give the same result\n",
    "print(f\"\\nResult verification:\")\n",
    "for i in range(1, len(results)):\n",
    "    match = np.allclose(results[0], results[i])\n",
    "    print(f\"{methods[i][0]} matches boolean indexing: {match}\")\n",
    "\n",
    "# More detailed timing with %timeit\n",
    "print(f\"\\nDetailed timing with %timeit:\")\n",
    "\n",
    "# Test with smaller array for %timeit (faster execution)\n",
    "test_arr = np.random.randn(100000)\n",
    "\n",
    "print(f\"\\nBoolean indexing:\")\n",
    "%timeit result = test_arr.copy(); result[result < 0] = 0\n",
    "\n",
    "print(f\"\\nnp.where:\")\n",
    "%timeit np.where(test_arr < 0, 0, test_arr)\n",
    "\n",
    "print(f\"\\nnp.maximum:\")\n",
    "%timeit np.maximum(test_arr, 0)\n",
    "\n",
    "print(f\"\\nnp.clip:\")\n",
    "%timeit np.clip(test_arr, 0, None)\n",
    "\n",
    "# Test with more complex conditions\n",
    "print(f\"\\nComplex condition: replace negative with 0, values > 2 with 2, keep others\")\n",
    "\n",
    "def complex_boolean(arr):\n",
    "    result = arr.copy()\n",
    "    result[result < 0] = 0\n",
    "    result[result > 2] = 2\n",
    "    return result\n",
    "\n",
    "def complex_where(arr):\n",
    "    return np.where(arr < 0, 0, np.where(arr > 2, 2, arr))\n",
    "\n",
    "def complex_clip(arr):\n",
    "    return np.clip(arr, 0, 2)\n",
    "\n",
    "# Time complex operations\n",
    "test_arr = np.random.randn(500000)\n",
    "\n",
    "start = time.time()\n",
    "result_bool = complex_boolean(test_arr)\n",
    "time_bool = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "result_where = complex_where(test_arr)\n",
    "time_where = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "result_clip = complex_clip(test_arr)\n",
    "time_clip = time.time() - start\n",
    "\n",
    "print(f\"\\nComplex condition timing:\")\n",
    "print(f\"Boolean indexing: {time_bool:.6f} seconds\")\n",
    "print(f\"np.where: {time_where:.6f} seconds\")\n",
    "print(f\"np.clip: {time_clip:.6f} seconds\")\n",
    "\n",
    "print(f\"\\nResults match: {np.allclose(result_bool, result_where) and np.allclose(result_where, result_clip)}\")\n",
    "\n",
    "print(f\"\\nKey insights:\")\n",
    "print(f\"- np.maximum and np.clip are often fastest for simple range operations\")\n",
    "print(f\"- Boolean indexing is intuitive but may require copying\")\n",
    "print(f\"- np.where is flexible but can be slower for simple cases\")\n",
    "print(f\"- Choose based on readability and specific use case\")\n",
    "print(f\"- Specialized functions (clip, maximum) are often optimized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "Demonstrate performance optimization by pre-allocating arrays vs growing them dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def grow_array_append(n):\n",
    "    \"\"\"Growing array by appending (very slow)\"\"\"\n",
    "    arr = np.array([])\n",
    "    for i in range(n):\n",
    "        arr = np.append(arr, i)\n",
    "    return arr\n",
    "\n",
    "def grow_array_concatenate(n):\n",
    "    \"\"\"Growing array by concatenation (slow)\"\"\"\n",
    "    arr = np.array([0])\n",
    "    for i in range(1, n):\n",
    "        arr = np.concatenate([arr, [i]])\n",
    "    return arr\n",
    "\n",
    "def grow_list_then_convert(n):\n",
    "    \"\"\"Using Python list then converting (better)\"\"\"\n",
    "    lst = []\n",
    "    for i in range(n):\n",
    "        lst.append(i)\n",
    "    return np.array(lst)\n",
    "\n",
    "def preallocate_array(n):\n",
    "    \"\"\"Pre-allocating array (fastest)\"\"\"\n",
    "    arr = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        arr[i] = i\n",
    "    return arr\n",
    "\n",
    "def use_arange(n):\n",
    "    \"\"\"Using built-in function (optimal)\"\"\"\n",
    "    return np.arange(n)\n",
    "\n",
    "# Test with different sizes\n",
    "sizes = [1000, 5000, 10000]\n",
    "\n",
    "print(f\"Performance comparison: Array creation strategies\")\n",
    "print(f\"{'Size':<8} {'Append':<10} {'List+Convert':<12} {'Pre-allocate':<12} {'np.arange':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for size in sizes:\n",
    "    # Test np.append (only for small sizes - it's very slow)\n",
    "    if size <= 1000:\n",
    "        start = time.time()\n",
    "        result_append = grow_array_append(size)\n",
    "        time_append = time.time() - start\n",
    "    else:\n",
    "        time_append = float('inf')\n",
    "    \n",
    "    # Test list then convert\n",
    "    start = time.time()\n",
    "    result_list = grow_list_then_convert(size)\n",
    "    time_list = time.time() - start\n",
    "    \n",
    "    # Test pre-allocation\n",
    "    start = time.time()\n",
    "    result_prealloc = preallocate_array(size)\n",
    "    time_prealloc = time.time() - start\n",
    "    \n",
    "    # Test np.arange\n",
    "    start = time.time()\n",
    "    result_arange = use_arange(size)\n",
    "    time_arange = time.time() - start\n",
    "    \n",
    "    append_str = f\"{time_append:.4f}\" if time_append != float('inf') else \"too slow\"\n",
    "    print(f\"{size:<8} {append_str:<10} {time_list:<12.6f} {time_prealloc:<12.6f} {time_arange:<10.6f}\")\n",
    "\n",
    "# More realistic example: building array with computed values\n",
    "def compute_slow_append(n):\n",
    "    \"\"\"Slow: append each computed value\"\"\"\n",
    "    arr = np.array([])\n",
    "    for i in range(n):\n",
    "        value = np.sin(i) * np.cos(i)  # Some computation\n",
    "        arr = np.append(arr, value)\n",
    "    return arr\n",
    "\n",
    "def compute_list_convert(n):\n",
    "    \"\"\"Better: use list then convert\"\"\"\n",
    "    lst = []\n",
    "    for i in range(n):\n",
    "        value = np.sin(i) * np.cos(i)\n",
    "        lst.append(value)\n",
    "    return np.array(lst)\n",
    "\n",
    "def compute_preallocate(n):\n",
    "    \"\"\"Fast: pre-allocate array\"\"\"\n",
    "    arr = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        arr[i] = np.sin(i) * np.cos(i)\n",
    "    return arr\n",
    "\n",
    "def compute_vectorized(n):\n",
    "    \"\"\"Fastest: fully vectorized\"\"\"\n",
    "    i = np.arange(n)\n",
    "    return np.sin(i) * np.cos(i)\n",
    "\n",
    "print(f\"\\nRealistic example: Computing sin(x)*cos(x) for x in range(n)\")\n",
    "\n",
    "n = 10000\n",
    "methods = [\n",
    "    (\"List + Convert\", compute_list_convert),\n",
    "    (\"Pre-allocate\", compute_preallocate),\n",
    "    (\"Vectorized\", compute_vectorized)\n",
    "]\n",
    "\n",
    "print(f\"\\nTiming for n={n:,}:\")\n",
    "times = []\n",
    "\n",
    "for name, method in methods:\n",
    "    start = time.time()\n",
    "    result = method(n)\n",
    "    elapsed = time.time() - start\n",
    "    times.append(elapsed)\n",
    "    \n",
    "    speedup = times[0] / elapsed if elapsed > 0 else 1\n",
    "    print(f\"{name:<15}: {elapsed:.6f} seconds ({speedup:.1f}x speedup)\")\n",
    "\n",
    "# Demonstrate memory allocation overhead\n",
    "print(f\"\\nMemory allocation overhead demonstration:\")\n",
    "\n",
    "def show_growth_cost(max_size):\n",
    "    \"\"\"Show how append cost grows\"\"\"\n",
    "    sizes = [100, 500, 1000, 2000]\n",
    "    \n",
    "    print(f\"{'Size':<8} {'Append Time':<12} {'Time/Element':<12}\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    for size in sizes:\n",
    "        if size <= max_size:\n",
    "            start = time.time()\n",
    "            arr = np.array([])\n",
    "            for i in range(size):\n",
    "                arr = np.append(arr, i)\n",
    "            elapsed = time.time() - start\n",
    "            per_element = elapsed / size\n",
    "            \n",
    "            print(f\"{size:<8} {elapsed:<12.6f} {per_element:<12.8f}\")\n",
    "\n",
    "show_growth_cost(2000)\n",
    "\n",
    "print(f\"\\nKey takeaways:\")\n",
    "print(f\"- NEVER use np.append in loops - it's extremely slow\")\n",
    "print(f\"- Pre-allocating arrays is much faster than growing them\")\n",
    "print(f\"- Python lists + conversion is better than np.append\")\n",
    "print(f\"- Vectorized operations are fastest when possible\")\n",
    "print(f\"- Each np.append creates a new array and copies all data\")\n",
    "print(f\"- Pre-allocation avoids repeated memory allocation/copying\")\n",
    "\n",
    "# Final timing comparison with %timeit\n",
    "print(f\"\\nFinal comparison with %timeit (n=5000):\")\n",
    "n = 5000\n",
    "\n",
    "print(f\"\\nList + convert:\")\n",
    "%timeit compute_list_convert(n)\n",
    "\n",
    "print(f\"\\nPre-allocate:\")\n",
    "%timeit compute_preallocate(n)\n",
    "\n",
    "print(f\"\\nVectorized:\")\n",
    "%timeit compute_vectorized(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}